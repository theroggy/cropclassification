# This is a config file with the shared/default settings for all markers. 

[general]
environment = DEV

# File format (extension) to use for data that is best saved in a column-optimized way
columndata_ext = .parquet
# File format (extension) to use for data that is best saved in a row-optimized way
rowdata_ext = .parquet
# File format (extension) to use for data that is output data (should be easy to use)
output_ext = .tsv
# File format for intermediary geo files (remark: gee needs .shp as input)
geofile_ext = .shp

# Constants for types of aggregation to use
# Mean value of the pixels values in a parcel.
PARCELDATA_AGGRAGATION_MEAN = mean
# std dev of the values of the pixels in a parcel
PARCELDATA_AGGRAGATION_STDDEV = stdDev

# Constants for types of sensor data
SENSORDATA_S1 = S1
# Sentinel 1 data
# Sentinel 1 data, in dB
SENSORDATA_S1DB = S1dB
# Sentinel 1 data, divided in Ascending and Descending passes
SENSORDATA_S1_ASCDESC = S1AscDesc
# Sentinel 1 data, in dB, divided in Ascending and Descending passes
SENSORDATA_S1DB_ASCDESC = S1dBAscDesc
# Sentinel 2 data
SENSORDATA_S2 = S2
# Sentinel 2 data (B2,B3,B4,B8) IF available for 95% or area
SENSORDATA_S2gt95 = S2gt95

[marker]
# markertype, must be overriden in child ini files
markertype = MUST_OVERRIDE

# Year to use
#year = the year variable isn't defined here, but is determined in runtime based on the job info

# start date of timeseries data to use
# remarks: nearest monday will be used + year will be replace in run-time
start_date_str = ${year}-03-27 
# end date of timeseries data to use
# remarks: end date is NOT inclusive + year will be replace in run-time
end_date_str = ${year}-08-10
# negative buffer to apply to input parcels
buffer = 5
# minimum number of pixels that should be inside the buffered input parcels
min_nb_pixels = 3
# minimum number of pixels that should be inside the buffered input parcels used when training
min_nb_pixels_train = ${marker:min_nb_pixels}

# classes that should be ignored for training, but have to get a prediction
classes_to_ignore_for_train = ${classes_to_ignore_for_train_default}
# define default ignores here, so it is easy to ADD extra for specific markers
classes_to_ignore_for_train_default = UNKNOWN

# classes that will be ignored for training and won't receive a prediction
classes_to_ignore = ${classes_to_ignore_default}
# define default ignores here, so it is easy to ADD extra for specific markers
classes_to_ignore_default = IGNORE_DIFFICULT_PERMANENT_CLASS, IGNORE_UNIMPORTANT_CLASS, IGNORE_NOT_ENOUGH_SAMPLES, IGNORE_EARLY_CROP, IGNORE_LATE_CROP, IGNORE_NEW_GRASSLAND

# classes that will be ignored for training and won't receive a prediction
classes_doubt = NODATA, DOUBT:NOT_ENOUGH_PIXELS, DOUBT, DOUBT:TYPE1, DOUBT:TYPE2, DOUBT:TYPE3, DOUBT:GRASS->ARABLE, DOUBT:FALLOW-UNCONFIRMED

# strategy to balance the training dataset for the marker. Possible values:
#   * BALANCING_STRATEGY_NONE: don't apply any balancing: 20% of the input samples per class is used for training
#   * BALANCING_STRATEGY_MEDIUM: 80% of input data is used for training, with maximum 10.000 samples per class and minimum 1.000 (samples will be duplicated if needed)
#   * BALANCING_STRATEGY_UPPER_LIMIT: 80% of input data is used for training, with a maximum of 10.000 samples per class
#   * BALANCING_STRATEGY_PROPORTIONAL_GROUPS: 80% of input data is used for training, but for classes with > 10.000 samples +- only half of those are used  
#   * BALANCING_STRATEGY_EQUAL: for each input class, the same amount of samples is used as training. For classes with few samples, (samples will be duplicated if needed)
balancing_strategy = BALANCING_STRATEGY_MEDIUM

# The sensor data to be used for this marker
sensordata_to_use = ${general:SENSORDATA_S1_ASCDESC}, ${general:SENSORDATA_S2gt95}
# The aggregation type to use on parcel level
parceldata_aggregations_to_use = ${general:PARCELDATA_AGGRAGATION_MEAN}

# Postprocess...
postprocess_to_groups = 

[preprocess]

dedicated_data_columns = ${columns:id}, ${columns:class}, ${columns:class_orig}, ${columns:pixcount_s1s2}
extra_export_columns = CODE_OBJ, LAYER_ID, PRC_ID, VERSIENR, GWSCOD_H

# The way the classtype needs to be prepared
classtype_to_prepare = ${marker:markertype}
# The way the classtype for groundtruth needs to be prepared
classtype_to_prepare_groundtruth = ${marker:markertype}_GROUNDTRUTH
# File where mappings to the classes to classify to can be found
classtype_to_prepare_refe_filepath = ${dirs:refe_dir}\BEFL_${marker:year}_mon_refe.tsv

[classifier]
# The classifier type to use. Currently supported types: 
#     * multilayer_perceptron
#     * nearestneighbour
#     * randomforest
#     * svm
classifier_type = multilayer_perceptron

# For multilayer_perceptron, the hidden layer size(s) (as a komma seperated list)
multilayer_perceptron_hidden_layer_sizes = 100, 100
# For multilayer_perceptron, the maximum number of iterations when training
multilayer_perceptron_max_iter = 1000
multilayer_perceptron_learning_rate_init = 0.001

# For randomforest, the maximum number of trees to create
randomforest_n_estimators = 200
# For randomforest, the maximum depth of trees to create
randomforest_max_depth = 35

[postprocess]
# Doubt: if highest probability < 2*second probability  
doubt_proba1_st_2_x_proba2 = True
# Doubt: if prediction == input class and highest probability < thresshold  
doubt_pred_eq_input_proba1_st_thresshold = 0
# Doubt: if prediction != input class and highest probability < thresshold  
doubt_pred_ne_input_proba1_st_thresshold = 0.96

[columns]
# The columns to include in the final output file
output_columns = LAYER_ID, PRC_ID, VERSIENR, markercode, run_id, ${prediction_cons}, ${prediction_cons_status}, ${prediction}, pred1_prob, pred2, pred2_prob, pred3, pred3_prob

# Column name of the id column
id = UID
# Column name of the geom column
geom = geometry
# Column name of the class, after preprocessing to optimize the classification
# For parcels that received an on the spot check, the class contains the 
# verified data so the training input is optimal
class = classname
# Column name of the original class of the parcel, before additional preprocessing
class_orig = classname_orig
# Column name of the class to use for balancing the training dataset
class_balancing = ${class}
# Column name of the class of the unverified groundtruth
class_groundtruth_unverified = classname_gt_unverified
# Column name of the class of the verified groundtruth
class_groundtruth_verified = classname_gt_verified
# Column name of the count of the number of pixels for sentinel1/2 images
pixcount_s1s2 = pixcount
# Column name of the standard prediction (probability can be same as other classes)
prediction = pred1
# Column name of the prediction with doubt (so has a minimum probability)
prediction_withdoubt = pred_withdoubt
# Column name of the consolidated prediction: can be doubt, not_enough_pixels,...
prediction_cons = pred_consolidated
# Column name of the status of the consolidated prediction: can be OK, NOK
prediction_cons_status = pred_cons_status
# Column name of the detailed conclusion based on standard prediction
prediction_conclusion_detail = pred_conclusion_detail
# Column name of the detailed conclusion based on prediction with doubt
prediction_conclusion_detail_withdoubt = pred_conclusion_detail_withdoubt
# Column name of the detailed conclusion based on consolidated prediction
prediction_conclusion_detail_cons = pred_conclusion_detail_cons
# Column name of the conclusion based on consolidated prediction
prediction_conclusion_cons = pred_conclusion_cons
# The status/result of the prediction
prediction_status = pred_status

[dirs]
# Reuse the last run dir (only change by overruling in overrule.ini!)
reuse_last_run_dir = False
# Reuse the config (only change by overruling in overrule.ini!)
reuse_last_run_dir_config = False

# Directories to use
root_dir = X:\monitoring\markers
environment_dir = ${dirs:root_dir}\${general:environment}
base_dir = ${dirs:environment_dir}
temp_dir = ${dirs:environment_dir}\tmp
marker_base_dir = ${dirs:base_dir}\${marker:year}_${marker:markertype}
timeseries_periodic_dir = ${dirs:environment_dir}\_timeseries_periodic
timeseries_per_image_dir = ${dirs:environment_dir}\_timeseries_per_image
input_dir = ${dirs:environment_dir}\_inputdata
input_preprocessed_dir = ${dirs:environment_dir}\_inputdata_preprocessed
model_dir = ${dirs:environment_dir}\_models
refe_dir = ${dirs:environment_dir}\_refe
job_dir = ${input_dir}
log_dir = ${dirs:marker_base_dir}\log\
gee = users/pieter_roggemans/